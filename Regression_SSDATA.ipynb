{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy\n",
    "from numpy import arange\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257780, 87)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load full dataset\n",
    "filename = 'ssdata_for_train_common.txt'\n",
    "dataset_full = read_csv(filename, sep='\\t')\n",
    "dataset_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257780, 29)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features to be used to build model\n",
    "cols = [\"Site.Type\",\"TA.raw\",\"SPS.raw\",\"sRNA1A.scaled\",\"sRNA1C.scaled\",\"sRNA1G.scaled\",\"sRNA8A.scaled\",\"sRNA8C.scaled\",\"sRNA8G.scaled\",\"site8A.scaled\",\"site8C.scaled\",\"site8G.scaled\",\"local.AU.raw\",\"X3..pairing.raw\",\"SA.raw\",\"Min_dist.raw\",\"PCT.raw\",\"ORF.length.raw\",\"X3.UTR.length.raw\",\"Offset.6mer.raw\",\"ORF.8mer.raw\",\"transfection_final_conc_curated\",\"trans_reagent\",\"genetic_background\",\"hours\",\"GPL\",\"Series\",\"cell\",\"log2fc\"]\n",
    "dataset_trim = dataset_full[cols]\n",
    "dataset_trim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site.Type</th>\n",
       "      <th>TA.raw</th>\n",
       "      <th>SPS.raw</th>\n",
       "      <th>sRNA1A.scaled</th>\n",
       "      <th>sRNA1C.scaled</th>\n",
       "      <th>sRNA1G.scaled</th>\n",
       "      <th>sRNA8A.scaled</th>\n",
       "      <th>sRNA8C.scaled</th>\n",
       "      <th>sRNA8G.scaled</th>\n",
       "      <th>site8A.scaled</th>\n",
       "      <th>...</th>\n",
       "      <th>Offset.6mer.raw</th>\n",
       "      <th>ORF.8mer.raw</th>\n",
       "      <th>transfection_final_conc_curated</th>\n",
       "      <th>trans_reagent</th>\n",
       "      <th>genetic_background</th>\n",
       "      <th>hours</th>\n",
       "      <th>GPL</th>\n",
       "      <th>Series</th>\n",
       "      <th>cell</th>\n",
       "      <th>log2fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7mer-m8</td>\n",
       "      <td>3.704</td>\n",
       "      <td>-8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>Lipofectamine2000</td>\n",
       "      <td>wildtype</td>\n",
       "      <td>48.0</td>\n",
       "      <td>GPL570</td>\n",
       "      <td>GSE27431</td>\n",
       "      <td>HEY</td>\n",
       "      <td>0.167583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7mer-1a</td>\n",
       "      <td>3.621</td>\n",
       "      <td>-6.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>Lipofectamine2000</td>\n",
       "      <td>wildtype</td>\n",
       "      <td>48.0</td>\n",
       "      <td>GPL570</td>\n",
       "      <td>GSE27431</td>\n",
       "      <td>HEY</td>\n",
       "      <td>0.353088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6mer</td>\n",
       "      <td>3.539</td>\n",
       "      <td>-5.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>HiPerFect</td>\n",
       "      <td>wildtype</td>\n",
       "      <td>40.0</td>\n",
       "      <td>GPL4133</td>\n",
       "      <td>GSE28522</td>\n",
       "      <td>HeLa</td>\n",
       "      <td>0.275285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6mer</td>\n",
       "      <td>3.539</td>\n",
       "      <td>-5.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>HiPerFect</td>\n",
       "      <td>wildtype</td>\n",
       "      <td>40.0</td>\n",
       "      <td>GPL4133</td>\n",
       "      <td>GSE28522</td>\n",
       "      <td>TW01</td>\n",
       "      <td>-0.023325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6mer</td>\n",
       "      <td>3.569</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HiPerFect</td>\n",
       "      <td>wildtype</td>\n",
       "      <td>96.0</td>\n",
       "      <td>GPL13607</td>\n",
       "      <td>GSE29207</td>\n",
       "      <td>hMADS</td>\n",
       "      <td>0.009550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Site.Type  TA.raw  SPS.raw  sRNA1A.scaled  sRNA1C.scaled  sRNA1G.scaled  \\\n",
       "0   7mer-m8   3.704    -8.80              0              0              0   \n",
       "1   7mer-1a   3.621    -6.43              0              0              0   \n",
       "2      6mer   3.539    -5.66              0              0              0   \n",
       "3      6mer   3.539    -5.66              0              0              0   \n",
       "4      6mer   3.569    -3.58              0              0              0   \n",
       "\n",
       "   sRNA8A.scaled  sRNA8C.scaled  sRNA8G.scaled  site8A.scaled    ...     \\\n",
       "0              0              0              1              0    ...      \n",
       "1              0              1              0              0    ...      \n",
       "2              0              0              0              0    ...      \n",
       "3              0              0              0              0    ...      \n",
       "4              1              0              0              0    ...      \n",
       "\n",
       "   Offset.6mer.raw  ORF.8mer.raw  transfection_final_conc_curated  \\\n",
       "0                1             0                     2.500000e-08   \n",
       "1                0             0                     2.500000e-08   \n",
       "2                0             0                     5.000000e-08   \n",
       "3                0             0                     5.000000e-08   \n",
       "4                1             0                              NaN   \n",
       "\n",
       "       trans_reagent  genetic_background  hours       GPL    Series   cell  \\\n",
       "0  Lipofectamine2000            wildtype   48.0    GPL570  GSE27431    HEY   \n",
       "1  Lipofectamine2000            wildtype   48.0    GPL570  GSE27431    HEY   \n",
       "2          HiPerFect            wildtype   40.0   GPL4133  GSE28522   HeLa   \n",
       "3          HiPerFect            wildtype   40.0   GPL4133  GSE28522   TW01   \n",
       "4          HiPerFect            wildtype   96.0  GPL13607  GSE29207  hMADS   \n",
       "\n",
       "     log2fc  \n",
       "0  0.167583  \n",
       "1  0.353088  \n",
       "2  0.275285  \n",
       "3 -0.023325  \n",
       "4  0.009550  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_trim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257780, 29)\n",
      "Site.Type                           object\n",
      "TA.raw                             float64\n",
      "SPS.raw                            float64\n",
      "sRNA1A.scaled                        int64\n",
      "sRNA1C.scaled                        int64\n",
      "sRNA1G.scaled                        int64\n",
      "sRNA8A.scaled                        int64\n",
      "sRNA8C.scaled                        int64\n",
      "sRNA8G.scaled                        int64\n",
      "site8A.scaled                        int64\n",
      "site8C.scaled                        int64\n",
      "site8G.scaled                        int64\n",
      "local.AU.raw                       float64\n",
      "X3..pairing.raw                    float64\n",
      "SA.raw                             float64\n",
      "Min_dist.raw                       float64\n",
      "PCT.raw                            float64\n",
      "ORF.length.raw                     float64\n",
      "X3.UTR.length.raw                  float64\n",
      "Offset.6mer.raw                      int64\n",
      "ORF.8mer.raw                         int64\n",
      "transfection_final_conc_curated    float64\n",
      "trans_reagent                       object\n",
      "genetic_background                  object\n",
      "hours                              float64\n",
      "GPL                                 object\n",
      "Series                              object\n",
      "cell                                object\n",
      "log2fc                             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Summarize Data\n",
    "\n",
    "# shape\n",
    "print(dataset_trim.shape)\n",
    "# types\n",
    "print(dataset_trim.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site.Type\n",
      "6mer       663452\n",
      "7mer-1a    230616\n",
      "7mer-m8    265919\n",
      "8mer-1a     97793\n",
      "dtype: int64\n",
      "\n",
      "trans_reagent\n",
      "Amaxa nucleofection             7284\n",
      "Cell Line Nucleofector kit     30919\n",
      "DharmaFECT                     22992\n",
      "DharmaFECT3                     8502\n",
      "HiPerFect                      66767\n",
      "INTERFERin                      2575\n",
      "Lentiviral vector              72953\n",
      "Lipofectamin RNAi MAX         406776\n",
      "Lipofectamine2000             378591\n",
      "MicroPorator MP-100             2528\n",
      "Neon transfection System        3642\n",
      "Oligofectamine                 20673\n",
      "PureFection                     6704\n",
      "Retroviral vector              13148\n",
      "SilentFect                     28828\n",
      "Viral vector                    3042\n",
      "X-tremeGENE siRNA               3857\n",
      "siPORT neo-FX                  32412\n",
      "dtype: int64\n",
      "\n",
      "genetic_background\n",
      "Dicer        119591\n",
      "wildtype    1138189\n",
      "dtype: int64\n",
      "\n",
      "GPL\n",
      "GPL10332    128884\n",
      "GPL10558    127171\n",
      "GPL10739      2972\n",
      "GPL10904      7124\n",
      "GPL13158      7466\n",
      "GPL13497      8884\n",
      "GPL13607    110402\n",
      "GPL13915     11186\n",
      "GPL14550      7770\n",
      "GPL1456      19115\n",
      "GPL15207      3699\n",
      "GPL15338      2748\n",
      "GPL15496      3307\n",
      "GPL16359      2990\n",
      "GPL16699     24138\n",
      "GPL1708       3215\n",
      "GPL1749       9549\n",
      "GPL19383      3740\n",
      "GPL3991      98930\n",
      "GPL4133     140503\n",
      "GPL4372      81797\n",
      "GPL4925       2354\n",
      "GPL5104       2611\n",
      "GPL5175       5396\n",
      "GPL5639       1010\n",
      "GPL570      153470\n",
      "GPL571       14982\n",
      "GPL5799       3484\n",
      "GPL6098       3193\n",
      "GPL6102      14767\n",
      "GPL6104       7923\n",
      "GPL6171       4372\n",
      "GPL6244      70752\n",
      "GPL6480      70869\n",
      "GPL6793       3030\n",
      "GPL6848       7436\n",
      "GPL6879      25300\n",
      "GPL6883       8702\n",
      "GPL6884      11356\n",
      "GPL6947      28476\n",
      "GPL7038       3676\n",
      "GPL7504       3141\n",
      "GPL8755       2872\n",
      "GPL885        3018\n",
      "dtype: int64\n",
      "\n",
      "Series\n",
      "GSE10057     3646\n",
      "GSE10455     7359\n",
      "GSE10864     2973\n",
      "GSE11701     2365\n",
      "GSE11778     3030\n",
      "GSE12100     4993\n",
      "GSE12278    10575\n",
      "GSE12615     1990\n",
      "GSE13105     9638\n",
      "GSE13286     3513\n",
      "GSE13674     3484\n",
      "GSE14477     2765\n",
      "GSE14507     4017\n",
      "GSE14537     8132\n",
      "GSE14831    16196\n",
      "GSE14847    14767\n",
      "GSE15281     2821\n",
      "GSE16239     2528\n",
      "GSE16568     3857\n",
      "GSE16571     1000\n",
      "GSE16674     3740\n",
      "GSE16700     3823\n",
      "GSE16988     3734\n",
      "GSE17460     2575\n",
      "GSE17508     3830\n",
      "GSE17828     2611\n",
      "GSE18510     3491\n",
      "GSE18545     5897\n",
      "GSE18625     3829\n",
      "GSE18695     4698\n",
      "            ...  \n",
      "GSE56967     3287\n",
      "GSE57158     3042\n",
      "GSE57676     8289\n",
      "GSE57820     3889\n",
      "GSE58004     2778\n",
      "GSE58142     1040\n",
      "GSE59458     3924\n",
      "GSE59805     3654\n",
      "GSE60766    13227\n",
      "GSE61078     3248\n",
      "GSE61139     2943\n",
      "GSE6207      4115\n",
      "GSE62453     3560\n",
      "GSE62568     4084\n",
      "GSE62951     3740\n",
      "GSE63483     1381\n",
      "GSE64020     7124\n",
      "GSE64364     6235\n",
      "GSE66844     3699\n",
      "GSE67327     4251\n",
      "GSE67328     4251\n",
      "GSE6838     72855\n",
      "GSE68740     3806\n",
      "GSE68742     4084\n",
      "GSE69150     3630\n",
      "GSE70434     3463\n",
      "GSE7185      2354\n",
      "GSE7864     52255\n",
      "GSE8501     29783\n",
      "GSE9742      4372\n",
      "dtype: int64\n",
      "\n",
      "cell\n",
      "2091                   2990\n",
      "218TGpp                2972\n",
      "4L                     3306\n",
      "5B1                    3306\n",
      "786O                  11080\n",
      "A172                   3030\n",
      "A498                  48134\n",
      "A549                  32872\n",
      "AGS                    4949\n",
      "Akata                  6619\n",
      "BG1                    1990\n",
      "BM-MSC                 3903\n",
      "BOY                    4928\n",
      "BT549                 14317\n",
      "C4-2                   1003\n",
      "C8161                  3042\n",
      "CB-HSPC                4752\n",
      "Calu-3                 3049\n",
      "DLD1                  43210\n",
      "DU145                 45692\n",
      "EC109                  2748\n",
      "ES2                    3857\n",
      "FLF                    6551\n",
      "FaDu                  26090\n",
      "GIST-T1                7890\n",
      "H1299                  2709\n",
      "H157                   3378\n",
      "H3255                  5580\n",
      "H4                    12422\n",
      "H441                   2780\n",
      "                      ...  \n",
      "SKBr3                  3513\n",
      "SKMEL28                3781\n",
      "SKMel147               2752\n",
      "SKNBE2                 7466\n",
      "SKNSH                 12650\n",
      "SKOV3                  3562\n",
      "SNB19                  3877\n",
      "SW1783                 3119\n",
      "SW780                  3346\n",
      "T.Tn                   3544\n",
      "T24                   19653\n",
      "TCP1                   2868\n",
      "TE13                   3779\n",
      "TE2                    7323\n",
      "TOV21G                10451\n",
      "TS543                  3704\n",
      "TW01                   3806\n",
      "U251                  10905\n",
      "U2OS                   7466\n",
      "U87MG                  6913\n",
      "UMUC3                  3484\n",
      "WERI                   2354\n",
      "WM1552C                2821\n",
      "caki1                 14195\n",
      "hCMEC/D3               1585\n",
      "hMADS                 13472\n",
      "hMSC-TERT              3924\n",
      "hiHep                  3699\n",
      "keratinocytes          2943\n",
      "myxoid liposarcoma     2872\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show classes in the features in object type, which must be transformed into digits.\n",
    "obj_cols = ['Site.Type', \"trans_reagent\",\"genetic_background\",\"GPL\",\"Series\",\"cell\",]\n",
    "for i, v in enumerate(obj_cols):\n",
    "    print dataset_trim.groupby(v).size()\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes for Site.Type : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:216: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "/usr/local/anaconda2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:275: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  return aux[:-1][aux[1:] == aux[:-1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes for trans_reagent : 19\n",
      "Number of classes for genetic_background : 2\n",
      "Number of classes for GPL : 44\n",
      "Number of classes for Series : 176\n",
      "Number of classes for cell : 126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site.Type</th>\n",
       "      <th>TA.raw</th>\n",
       "      <th>SPS.raw</th>\n",
       "      <th>sRNA1A.scaled</th>\n",
       "      <th>sRNA1C.scaled</th>\n",
       "      <th>sRNA1G.scaled</th>\n",
       "      <th>sRNA8A.scaled</th>\n",
       "      <th>sRNA8C.scaled</th>\n",
       "      <th>sRNA8G.scaled</th>\n",
       "      <th>site8A.scaled</th>\n",
       "      <th>...</th>\n",
       "      <th>Offset.6mer.raw</th>\n",
       "      <th>ORF.8mer.raw</th>\n",
       "      <th>transfection_final_conc_curated</th>\n",
       "      <th>trans_reagent</th>\n",
       "      <th>genetic_background</th>\n",
       "      <th>hours</th>\n",
       "      <th>GPL</th>\n",
       "      <th>Series</th>\n",
       "      <th>cell</th>\n",
       "      <th>log2fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3.704</td>\n",
       "      <td>-8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>35</td>\n",
       "      <td>0.167583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.621</td>\n",
       "      <td>-6.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>35</td>\n",
       "      <td>0.353088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.539</td>\n",
       "      <td>-5.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19</td>\n",
       "      <td>63</td>\n",
       "      <td>43</td>\n",
       "      <td>0.275285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.539</td>\n",
       "      <td>-5.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19</td>\n",
       "      <td>63</td>\n",
       "      <td>112</td>\n",
       "      <td>-0.023325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.569</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>121</td>\n",
       "      <td>0.009550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site.Type  TA.raw  SPS.raw  sRNA1A.scaled  sRNA1C.scaled  sRNA1G.scaled  \\\n",
       "0          2   3.704    -8.80              0              0              0   \n",
       "1          1   3.621    -6.43              0              0              0   \n",
       "2          0   3.539    -5.66              0              0              0   \n",
       "3          0   3.539    -5.66              0              0              0   \n",
       "4          0   3.569    -3.58              0              0              0   \n",
       "\n",
       "   sRNA8A.scaled  sRNA8C.scaled  sRNA8G.scaled  site8A.scaled    ...     \\\n",
       "0              0              0              1              0    ...      \n",
       "1              0              1              0              0    ...      \n",
       "2              0              0              0              0    ...      \n",
       "3              0              0              0              0    ...      \n",
       "4              1              0              0              0    ...      \n",
       "\n",
       "   Offset.6mer.raw  ORF.8mer.raw  transfection_final_conc_curated  \\\n",
       "0                1             0                     2.500000e-08   \n",
       "1                0             0                     2.500000e-08   \n",
       "2                0             0                     5.000000e-08   \n",
       "3                0             0                     5.000000e-08   \n",
       "4                1             0                              NaN   \n",
       "\n",
       "   trans_reagent  genetic_background  hours  GPL  Series  cell    log2fc  \n",
       "0              9                   1   48.0   25      59    35  0.167583  \n",
       "1              9                   1   48.0   25      59    35  0.353088  \n",
       "2              5                   1   40.0   19      63    43  0.275285  \n",
       "3              5                   1   40.0   19      63   112 -0.023325  \n",
       "4              5                   1   96.0    6      66   121  0.009550  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_enc = dataset_trim\n",
    "mlb = []\n",
    "obj_cols = ['Site.Type', \"trans_reagent\",\"genetic_background\",\"GPL\",\"Series\",\"cell\",]\n",
    "for i, v in enumerate(obj_cols):    \n",
    "    mlb.append(LabelEncoder())\n",
    "    mlb[i].fit(dataset_trim[v])\n",
    "    dataset_enc[v] = mlb[i].transform(dataset_trim[v])\n",
    "    print \"Number of classes for \" + v + \" : \" + str(len(mlb[i].classes_))\n",
    "    #print mlb[i].classes_\n",
    "dataset_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site.Type                               0\n",
       "TA.raw                                  0\n",
       "SPS.raw                                 0\n",
       "sRNA1A.scaled                           0\n",
       "sRNA1C.scaled                           0\n",
       "sRNA1G.scaled                           0\n",
       "sRNA8A.scaled                           0\n",
       "sRNA8C.scaled                           0\n",
       "sRNA8G.scaled                           0\n",
       "site8A.scaled                           0\n",
       "site8C.scaled                           0\n",
       "site8G.scaled                           0\n",
       "local.AU.raw                            0\n",
       "X3..pairing.raw                         0\n",
       "SA.raw                                  0\n",
       "Min_dist.raw                            0\n",
       "PCT.raw                            239268\n",
       "ORF.length.raw                          0\n",
       "X3.UTR.length.raw                       0\n",
       "Offset.6mer.raw                         0\n",
       "ORF.8mer.raw                            0\n",
       "transfection_final_conc_curated    361102\n",
       "trans_reagent                           0\n",
       "genetic_background                      0\n",
       "hours                              124942\n",
       "GPL                                     0\n",
       "Series                                  0\n",
       "cell                                    0\n",
       "log2fc                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_unfilled = dataset_enc\n",
    "dataset_unfilled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imputing NaN with mean value of the entire column\n",
    "\n",
    "imr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imr = imr.fit(dataset_unfilled)\n",
    "dataset = imr.transform(dataset_unfilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed=seed)\n",
    "rand_ix=numpy.random.randint(1, dataset.shape[0], size=30000)\n",
    "rand_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "\n",
    "# Split-out validation dataset\n",
    "\n",
    "# Use Entire Data\n",
    "#X = dataset[:,0:28]\n",
    "#Y = dataset[:,28]\n",
    "\n",
    "# Use only partial Data\n",
    "X = dataset[rand_ix,0:28]\n",
    "Y = dataset[rand_ix,28]\n",
    "\n",
    "validation_size = 0.20\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "\n",
    "def plot_learning_curve(history):    \n",
    "    pyplot.plot(history.history['loss'])\n",
    "    pyplot.plot(history.history['val_loss'])\n",
    "    pyplot.title('model loss - Mean Squared Error(MSE)')\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "    pyplot.show()\n",
    "\n",
    "# define base model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(input_dim, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(input_dim, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "# define wider model\n",
    "def wider_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "def more_larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(input_dim, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: -0.612589 (0.045929)\n",
      "RIDGE: -0.612588 (0.045929)\n",
      "LASSO: -0.625626 (0.049576)\n",
      "EN: -0.624634 (0.049577)\n",
      "KNN: -0.432357 (0.018166)\n",
      "CART: -0.800002 (0.041370)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Algorithms\n",
    "# Test options and evaluation metric\n",
    "num_folds = 5\n",
    "seed = 7\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('RIDGE', Ridge()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('EN', ElasticNet()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "models.append(('XGB', XGBRegressor()))\n",
    "models.append(('FFNN', KerasRegressor(build_fn=baseline_model, epochs=2000, batch_size=1024, verbose=0)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "# Compare Algorithms\n",
    "fig = pyplot.figure(figsize=(10, 7))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 3\n",
    "seed = 7\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LinearRegression())])))\n",
    "pipelines.append(('ScaledRIDGE', Pipeline([('Scaler', StandardScaler()),('RIDGE', Ridge())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()),('SVR', SVR())])))\n",
    "pipelines.append(('ScaledXGB', Pipeline([('Scaler', StandardScaler()),('XGB', XGBRegressor())])))\n",
    "pipelines.append(('ScaledFFNN', Pipeline([('Scaler', StandardScaler()),('FFNN', KerasRegressor(build_fn=baseline_model, epochs=2000, batch_size=1024, verbose=0))])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "\tkfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "# Compare Algorithms\n",
    "fig = pyplot.figure(figsize=(10, 7))\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f42451fb930, file \"/...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/a...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f42451fb930, file \"/...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/a...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2017-05-02T17:34:05.141968', u'msg_id': u'C792531207324AF48B5F96B3E6EA5319', u'msg_type': u'execute_request', u'session': u'746550B78D7E4FC8961B972C25286F7A', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'C792531207324AF48B5F96B3E6EA5319', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['746550B78D7E4FC8961B972C25286F7A']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2017-05-02T17:34:05.141968', u'msg_id': u'C792531207324AF48B5F96B3E6EA5319', u'msg_type': u'execute_request', u'session': u'746550B78D7E4FC8961B972C25286F7A', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'C792531207324AF48B5F96B3E6EA5319', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['746550B78D7E4FC8961B972C25286F7A'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2017-05-02T17:34:05.141968', u'msg_id': u'C792531207324AF48B5F96B3E6EA5319', u'msg_type': u'execute_request', u'session': u'746550B78D7E4FC8961B972C25286F7A', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'C792531207324AF48B5F96B3E6EA5319', 'msg_type': u'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-43-731f0dacf47e>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f41defb89d0, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f4131bc9c30, file \"<ipython-input-43-731f0dacf47e>\", line 7>\n        result = <ExecutionResult object at 7f41defb89d0, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f4131bc9c30, file \"<ipython-input-43-731f0dacf47e>\", line 7>, result=<ExecutionResult object at 7f41defb89d0, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f4131bc9c30, file \"<ipython-input-43-731f0dacf47e>\", line 7>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'Dense': <class 'keras.layers.core.Dense'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u\"# Load libraries\\nimport numpy\\nfrom numpy imp...essor\\nget_ipython().magic(u'matplotlib inline')\", u\"# Load full dataset\\nfilename = 'ssdata_for_tr...ead_csv(filename, sep='\\\\t')\\ndataset_full.shape\", u'# Select features to be used to build model\\nc...et_trim = dataset_full[cols]\\ndataset_trim.shape', u'dataset_trim.head()', u'# Summarize Data\\n\\n# shape\\nprint(dataset_trim.shape)\\n# types\\nprint(dataset_trim.dtypes)', u'# Show classes in the features in object type,...print dataset_trim.groupby(v).size()\\n    print ', u'dataset_enc = dataset_trim\\nmlb = []\\nobj_cols...\\n    #print mlb[i].classes_\\ndataset_enc.head()', u'dataset_unfilled = dataset_enc\\ndataset_unfilled.isnull().sum()', u\"# Imputing NaN with mean value of the entire c...lled)\\ndataset = imr.transform(dataset_unfilled)\", u'# Prepare Data\\n\\n# Split-out validation datas...Y, test_size=validation_size, random_state=seed)', u\"input_dim = 28\\n\\ndef plot_learning_curve(hist...quared_error', optimizer='adam')\\n\\treturn model\", u\"# Imputing NaN with mean value of the entire c...lled)\\ndataset = imr.transform(dataset_unfilled)\", u'numpy.random.randint(1, 10000)', u'numpy.random.randint(1, 10000, size=10000)', u'numpy.random.randint(1, dataset.shape[0], size=10000)', u'randindex=numpy.random.randint(1, dataset.shape[0], size=10000)', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'Dense': <class 'keras.layers.core.Dense'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u\"# Load libraries\\nimport numpy\\nfrom numpy imp...essor\\nget_ipython().magic(u'matplotlib inline')\", u\"# Load full dataset\\nfilename = 'ssdata_for_tr...ead_csv(filename, sep='\\\\t')\\ndataset_full.shape\", u'# Select features to be used to build model\\nc...et_trim = dataset_full[cols]\\ndataset_trim.shape', u'dataset_trim.head()', u'# Summarize Data\\n\\n# shape\\nprint(dataset_trim.shape)\\n# types\\nprint(dataset_trim.dtypes)', u'# Show classes in the features in object type,...print dataset_trim.groupby(v).size()\\n    print ', u'dataset_enc = dataset_trim\\nmlb = []\\nobj_cols...\\n    #print mlb[i].classes_\\ndataset_enc.head()', u'dataset_unfilled = dataset_enc\\ndataset_unfilled.isnull().sum()', u\"# Imputing NaN with mean value of the entire c...lled)\\ndataset = imr.transform(dataset_unfilled)\", u'# Prepare Data\\n\\n# Split-out validation datas...Y, test_size=validation_size, random_state=seed)', u\"input_dim = 28\\n\\ndef plot_learning_curve(hist...quared_error', optimizer='adam')\\n\\treturn model\", u\"# Imputing NaN with mean value of the entire c...lled)\\ndataset = imr.transform(dataset_unfilled)\", u'numpy.random.randint(1, 10000)', u'numpy.random.randint(1, 10000, size=10000)', u'numpy.random.randint(1, dataset.shape[0], size=10000)', u'randindex=numpy.random.randint(1, dataset.shape[0], size=10000)', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/suns1/Desktop/127.0.0.1/tanmay/<ipython-input-43-731f0dacf47e> in <module>()\n      2 max_depth = range(1, 11, 2)\n      3 print(max_depth)\n      4 param_grid = dict(max_depth=max_depth)\n      5 kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n      6 grid_search = GridSearchCV(model, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, cv=kfold, verbose=1)\n----> 7 grid_result = grid_search.fit(X_train, Y_train)\n      8 \n      9 # summarize results\n     10 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n     11 means = grid_result.cv_results_['mean_test_score']\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=3, rand...     scoring='neg_mean_squared_error', verbose=1), X=array([[  2.   ,   3.569,  -5.24 , ...,  25.   ,...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), y=array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...    scoring='neg_mean_squared_error', verbose=1)>\n        X = array([[  2.   ,   3.569,  -5.24 , ...,  25.   ,...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]])\n        y = array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083])\n        groups = None\n        self.param_grid = {'max_depth': [1, 3, 5, 7, 9]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=3, rand...     scoring='neg_mean_squared_error', verbose=1), X=array([[  2.   ,   3.569,  -5.24 , ...,  25.   ,...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), y=array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue May  2 17:34:11 2017\nPID: 18426                   Python 2.7.13: /usr/local/anaconda2/bin/python\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), memmap([[  2.   ,   3.569,  -5.24 , ...,  25.   ...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), make_scorer(mean_squared_error, greater_is_better=False), array([    0,     1,     4, ..., 39988, 39994, 39998]), array([    2,     3,     5, ..., 39996, 39997, 39999]), 1, {'max_depth': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), memmap([[  2.   ,   3.569,  -5.24 , ...,  25.   ...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), make_scorer(mean_squared_error, greater_is_better=False), array([    0,     1,     4, ..., 39988, 39994, 39998]), array([    2,     3,     5, ..., 39996, 39997, 39999]), 1, {'max_depth': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), X=memmap([[  2.   ,   3.569,  -5.24 , ...,  25.   ...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), y=array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([    0,     1,     4, ..., 39988, 39994, 39998]), test=array([    2,     3,     5, ..., 39996, 39997, 39999]), verbose=1, parameters={'max_depth': 1}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...earn.KerasRegressor object at 0x7f4131815450>)])>\n        parameters = {'max_depth': 1}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), **kwargs={'max_depth': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method Pipeline._set_params of Pipeline(s...earn.KerasRegressor object at 0x7f4131815450>)])>\n        kwargs = {'max_depth': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), steps_attr='steps', **params={'max_depth': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...earn.KerasRegressor object at 0x7f4131815450>)])>\n        params = {'max_depth': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), **params={'max_depth': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-731f0dacf47e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f42451fb930, file \"/...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/a...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f42451fb930, file \"/...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/a...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2017-05-02T17:34:05.141968', u'msg_id': u'C792531207324AF48B5F96B3E6EA5319', u'msg_type': u'execute_request', u'session': u'746550B78D7E4FC8961B972C25286F7A', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'C792531207324AF48B5F96B3E6EA5319', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['746550B78D7E4FC8961B972C25286F7A']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2017-05-02T17:34:05.141968', u'msg_id': u'C792531207324AF48B5F96B3E6EA5319', u'msg_type': u'execute_request', u'session': u'746550B78D7E4FC8961B972C25286F7A', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'C792531207324AF48B5F96B3E6EA5319', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['746550B78D7E4FC8961B972C25286F7A'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2017-05-02T17:34:05.141968', u'msg_id': u'C792531207324AF48B5F96B3E6EA5319', u'msg_type': u'execute_request', u'session': u'746550B78D7E4FC8961B972C25286F7A', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'C792531207324AF48B5F96B3E6EA5319', 'msg_type': u'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'# grid search\\nmax_depth = range(1, 11, 2)\\npr...g Loss\\')\\n    pyplot.savefig(\\'max_depth.png\\')', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-43-731f0dacf47e>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f41defb89d0, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f4131bc9c30, file \"<ipython-input-43-731f0dacf47e>\", line 7>\n        result = <ExecutionResult object at 7f41defb89d0, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f4131bc9c30, file \"<ipython-input-43-731f0dacf47e>\", line 7>, result=<ExecutionResult object at 7f41defb89d0, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f4131bc9c30, file \"<ipython-input-43-731f0dacf47e>\", line 7>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'Dense': <class 'keras.layers.core.Dense'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u\"# Load libraries\\nimport numpy\\nfrom numpy imp...essor\\nget_ipython().magic(u'matplotlib inline')\", u\"# Load full dataset\\nfilename = 'ssdata_for_tr...ead_csv(filename, sep='\\\\t')\\ndataset_full.shape\", u'# Select features to be used to build model\\nc...et_trim = dataset_full[cols]\\ndataset_trim.shape', u'dataset_trim.head()', u'# Summarize Data\\n\\n# shape\\nprint(dataset_trim.shape)\\n# types\\nprint(dataset_trim.dtypes)', u'# Show classes in the features in object type,...print dataset_trim.groupby(v).size()\\n    print ', u'dataset_enc = dataset_trim\\nmlb = []\\nobj_cols...\\n    #print mlb[i].classes_\\ndataset_enc.head()', u'dataset_unfilled = dataset_enc\\ndataset_unfilled.isnull().sum()', u\"# Imputing NaN with mean value of the entire c...lled)\\ndataset = imr.transform(dataset_unfilled)\", u'# Prepare Data\\n\\n# Split-out validation datas...Y, test_size=validation_size, random_state=seed)', u\"input_dim = 28\\n\\ndef plot_learning_curve(hist...quared_error', optimizer='adam')\\n\\treturn model\", u\"# Imputing NaN with mean value of the entire c...lled)\\ndataset = imr.transform(dataset_unfilled)\", u'numpy.random.randint(1, 10000)', u'numpy.random.randint(1, 10000, size=10000)', u'numpy.random.randint(1, dataset.shape[0], size=10000)', u'randindex=numpy.random.randint(1, dataset.shape[0], size=10000)', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'Dense': <class 'keras.layers.core.Dense'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u\"# Load libraries\\nimport numpy\\nfrom numpy imp...essor\\nget_ipython().magic(u'matplotlib inline')\", u\"# Load full dataset\\nfilename = 'ssdata_for_tr...ead_csv(filename, sep='\\\\t')\\ndataset_full.shape\", u'# Select features to be used to build model\\nc...et_trim = dataset_full[cols]\\ndataset_trim.shape', u'dataset_trim.head()', u'# Summarize Data\\n\\n# shape\\nprint(dataset_trim.shape)\\n# types\\nprint(dataset_trim.dtypes)', u'# Show classes in the features in object type,...print dataset_trim.groupby(v).size()\\n    print ', u'dataset_enc = dataset_trim\\nmlb = []\\nobj_cols...\\n    #print mlb[i].classes_\\ndataset_enc.head()', u'dataset_unfilled = dataset_enc\\ndataset_unfilled.isnull().sum()', u\"# Imputing NaN with mean value of the entire c...lled)\\ndataset = imr.transform(dataset_unfilled)\", u'# Prepare Data\\n\\n# Split-out validation datas...Y, test_size=validation_size, random_state=seed)', u\"input_dim = 28\\n\\ndef plot_learning_curve(hist...quared_error', optimizer='adam')\\n\\treturn model\", u\"# Imputing NaN with mean value of the entire c...lled)\\ndataset = imr.transform(dataset_unfilled)\", u'numpy.random.randint(1, 10000)', u'numpy.random.randint(1, 10000, size=10000)', u'numpy.random.randint(1, dataset.shape[0], size=10000)', u'randindex=numpy.random.randint(1, dataset.shape[0], size=10000)', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', u'rand_ix=numpy.random.randint(1, dataset.shape[0], size=10000)\\nrand_ix', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/suns1/Desktop/127.0.0.1/tanmay/<ipython-input-43-731f0dacf47e> in <module>()\n      2 max_depth = range(1, 11, 2)\n      3 print(max_depth)\n      4 param_grid = dict(max_depth=max_depth)\n      5 kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n      6 grid_search = GridSearchCV(model, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, cv=kfold, verbose=1)\n----> 7 grid_result = grid_search.fit(X_train, Y_train)\n      8 \n      9 # summarize results\n     10 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n     11 means = grid_result.cv_results_['mean_test_score']\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=3, rand...     scoring='neg_mean_squared_error', verbose=1), X=array([[  2.   ,   3.569,  -5.24 , ...,  25.   ,...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), y=array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...    scoring='neg_mean_squared_error', verbose=1)>\n        X = array([[  2.   ,   3.569,  -5.24 , ...,  25.   ,...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]])\n        y = array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083])\n        groups = None\n        self.param_grid = {'max_depth': [1, 3, 5, 7, 9]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=3, rand...     scoring='neg_mean_squared_error', verbose=1), X=array([[  2.   ,   3.569,  -5.24 , ...,  25.   ,...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), y=array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue May  2 17:34:11 2017\nPID: 18426                   Python 2.7.13: /usr/local/anaconda2/bin/python\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), memmap([[  2.   ,   3.569,  -5.24 , ...,  25.   ...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), make_scorer(mean_squared_error, greater_is_better=False), array([    0,     1,     4, ..., 39988, 39994, 39998]), array([    2,     3,     5, ..., 39996, 39997, 39999]), 1, {'max_depth': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), memmap([[  2.   ,   3.569,  -5.24 , ...,  25.   ...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), make_scorer(mean_squared_error, greater_is_better=False), array([    0,     1,     4, ..., 39988, 39994, 39998]), array([    2,     3,     5, ..., 39996, 39997, 39999]), 1, {'max_depth': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), X=memmap([[  2.   ,   3.569,  -5.24 , ...,  25.   ...3.432,  -8.41 , ...,   1.   ,  65.   ,  34.   ]]), y=array([ 0.06931248,  0.1439842 ,  0.03702476, ...,  0.12689765,\n       -0.1279703 ,  0.62379083]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([    0,     1,     4, ..., 39988, 39994, 39998]), test=array([    2,     3,     5, ..., 39996, 39997, 39999]), verbose=1, parameters={'max_depth': 1}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...earn.KerasRegressor object at 0x7f4131815450>)])>\n        parameters = {'max_depth': 1}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), **kwargs={'max_depth': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method Pipeline._set_params of Pipeline(s...earn.KerasRegressor object at 0x7f4131815450>)])>\n        kwargs = {'max_depth': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), steps_attr='steps', **params={'max_depth': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...earn.KerasRegressor object at 0x7f4131815450>)])>\n        params = {'max_depth': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/usr/local/anaconda2/lib/python2.7/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('Scaler', StandardScaler(copy=T...learn.KerasRegressor object at 0x7f4131815450>)]), **params={'max_depth': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "max_depth = range(1, 11, 2)\n",
    "print(max_depth)\n",
    "param_grid = dict(max_depth=max_depth)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, cv=kfold, verbose=1)\n",
    "grid_result = grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    pyplot.errorbar(max_depth, means, yerr=stds)\n",
    "    pyplot.title(\"XGBoost max_depth vs MSE\")\n",
    "    pyplot.xlabel('max_depth')\n",
    "    pyplot.ylabel('Log Loss')\n",
    "    pyplot.savefig('max_depth.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Feed Forward Neural Network Topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "\n",
    "history = []\n",
    "\n",
    "epochs=1000\n",
    "batch_size=1024\n",
    "\n",
    "# Fit the model\n",
    "model = baseline_model()\n",
    "his = model.fit(X_train, Y_train, validation_data=(X_validation,Y_validation), epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "history.append(his)\n",
    "\n",
    "model = larger_model()\n",
    "his = model.fit(X_train, Y_train, validation_data=(X_validation,Y_validation), epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "history.append(his)\n",
    "\n",
    "#model = wider_model()\n",
    "#his = model.fit(X_train, Y_train, validation_data=(X_validation,Y_validation), epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "#history.append(his)\n",
    "\n",
    "#model = more_larger_model()\n",
    "#his = model.fit(X_train, Y_train, validation_data=(X_validation,Y_validation), epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "#history.append(his)\n",
    "\n",
    "plot_learning_curve(history[0])\n",
    "plot_learning_curve(history[1])\n",
    "plot_learning_curve(history[2])\n",
    "plot_learning_curve(history[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop' , 'adam']\n",
    "inits = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [50, 100, 150]\n",
    "batches = [5, 10, 20]\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Deep Neural Network Algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "k_values = numpy.array([1,3,5,7,9,11,13,15,17,19,21])\n",
    "param_grid = dict(n_neighbors=k_values)\n",
    "model = KNeighborsRegressor()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB', AdaBoostRegressor())])))\n",
    "ensembles.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))\n",
    "ensembles.append(('ScaledRF', Pipeline([('Scaler', StandardScaler()),('RF', RandomForestRegressor())])))\n",
    "ensembles.append(('ScaledET', Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesRegressor())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "\tkfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "# Compare Algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Scaled Ensemble Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tune scaled GBM\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=numpy.array([50,100,150,200,250,300,350,400]))\n",
    "model = GradientBoostingRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "\n",
    "# prepare the model\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = GradientBoostingRegressor(random_state=seed, n_estimators=400)\n",
    "model.fit(rescaledX, Y_train)\n",
    "# transform the validation dataset\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(mean_squared_error(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
